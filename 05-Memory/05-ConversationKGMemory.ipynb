{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635d8ebb",
      "metadata": {},
      "source": [
        "# ConversationKGMemory\n",
        "\n",
        "- Author: [Secludor](https://github.com/Secludor)\n",
        "- Design: [Secludor](https://github.com/Secludor)\n",
        "- Peer Review : [ulysyszh](https://github.com/ulysyszh), [Jinu Cho](https://github.com/jinucho)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/05-Memory/05-ConversationKGMemory.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/05-Memory/05-ConversationKGMemory.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "Unlike `ConversationEntityMemory`, which manages information about entities in a key-value format for individual entities, `ConversationKGMemory`(Conversation Knowledge Graph Memory) is a module that manages relationships between entities in a graph format.\n",
        "\n",
        "It extracts and structures **knowledge triplets** (subject-relationship-object) to identify and store complex relationships between entities, and allows exploration of entity connectivity through **graph structure**.\n",
        "\n",
        "This helps the model understand relationships between different entities and better respond to queries based on complex networks and historical context.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Conversation Knowlege Graph Memory](#conversation-knowlege-graph-memory)\n",
        "- [Applying KG Memory to Chain](#applying-kg-memory-to-chain)\n",
        "- [Applying KG Memory with LCEL](#applying-kg-memory-with-lcel)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain Python API Reference>langchain-community: 0.3.13>memory>ConversationKGMemory](https://python.langchain.com/api_reference/community/memory/langchain_community.memory.kg.ConversationKGMemory.html)\n",
        "- [LangChain Python API Reference>langchain-community: 0.2.16>NetworkxEntityGraph](https://python.langchain.com/v0.2/api_reference/community/graphs/langchain_community.graphs.networkx_graph.NetworkxEntityGraph.html#langchain_community.graphs.networkx_graph.NetworkxEntityGraph)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c7aba4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "21943adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial\n",
        "# Module Error 로 인한 Add\n",
        "%pip install networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f25ec196",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_community\",\n",
        "        \"langchain_openai\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f9065ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"05-ConversationKGMemory\",  # title 과 동일하게 설정해 주세요\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690a9ae0",
      "metadata": {},
      "source": [
        "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
        "\n",
        "[Note] This is not necessary if you've already set the required API keys in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4f99b5b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load API keys from .env file\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "616661ad",
      "metadata": {},
      "source": [
        "## Conversation Knowlege Graph Memory\n",
        "\n",
        "`ConversationKGMemory` is a memory module that stores and manages information extracted from conversations in a graph structure. This example demonstrates the following key features:\n",
        "\n",
        "- Storing conversation context (`save_context`)\n",
        "- (Reference) Getting a list of entity names in the graph sorted by causal dependence. (`get_topological_sort`)\n",
        "- Extracting entities from current conversation (`get_current_entities`)\n",
        "- Extracting knowledge triplets (`get_knowledge_triplets`)\n",
        "- Retrieving stored memory (`load_memory_variables`)\n",
        "\n",
        "The following example shows the process of extracting entities and relationships from a conversation about a new designer, Shelly Kim, and storing them in a graph format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "17efec71",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.memory.kg import ConversationKGMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e165b797",
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "#ConversationKGMemory는 대화형 모델에서 대화의 맥락을 저장하고 관리하는 데 사용되는 메모리 시스템\n",
        "#대화 데이터를 저장하고 추적하는 데 사용됩니다. 대화의 흐름을 유지하면서, 사용자가 제공한 정보를 기억하고 그에 맞는 응답을 생성하는 데 도움\n",
        "memory = ConversationKGMemory(llm=llm, return_messages=True)\n",
        "memory.save_context(\n",
        "    {\"input\": \"This is Shelly Kim who lives in Pangyo.\"},\n",
        "    {\"output\": \"Hello Shelly, nice to meet you! What kind of work do you do?\"},\n",
        ")\n",
        "memory.save_context(\n",
        "    {\"input\": \"Shelly Kim is our company's new designer.\"},\n",
        "    {\n",
        "        \"output\": \"That's great! Welcome to our team. I hope you'll enjoy working with us.\"\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfed7692",
      "metadata": {},
      "source": [
        "### (Reference) get_knowledge_triplets(input_string: str) → List[KnowledgeTriple]\n",
        "\n",
        "You can use the `get_topological_sort` method to view all entities stored in the knowledge graph in topological order:\n",
        "\n",
        "This method:\n",
        "- Uses NetworkX library to analyze the knowledge graph structure\n",
        "- Performs topological sorting based on directed edges\n",
        "- Returns a list of entities in dependency order\n",
        "\n",
        "The order reflects the relationships between entities in the conversation, showing how they are connected in the knowledge graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "dc39b1f8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Shelly Kim', 'Pangyo', \"our company's new designer\"]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# KG 그래프에서 순서대로 정렬을 해주는 기능\n",
        "#위상 정렬은 이런 의존성 관계를 올바른 순서대로 정리해주는 방법\n",
        "memory.kg.get_topological_sort()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b2323cd",
      "metadata": {},
      "source": [
        "### get_current_entities(input_string: str) → List[str]\n",
        "\n",
        "Here's how the `get_current_entities` method works:\n",
        "\n",
        "**1. Entity Extraction Chain Creation**\n",
        "- Creates an `LLMChain` using the `entity_extraction_prompt` template.\n",
        "- This prompt is designed to extract proper nouns from the last line of the conversation.\n",
        "\n",
        "**2. Context Processing**\n",
        "- Retrieves the last **k*2** messages from the buffer. (default : k=2)\n",
        "- Generates conversation history string using `human_prefix` and `ai_prefix`.\n",
        "\n",
        "**3. Entity Extraction**\n",
        "- Extracts proper nouns from the input string \"Who is Shelly Kim?\"\n",
        "- Primarily recognizes words starting with capital letters as proper nouns.\n",
        "- In this case, \"Shelly Kim\" is extracted as an entity.\n",
        "\n",
        "This method **only extracts entities from the question itself**, while the previous conversation context is used only for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1eae79db",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Shelly Kim']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#대화에서 현재 주어진 입력에 대한 **개체(Entity)**를 추출하는 메서드\n",
        "#\"Who is Shelly Kim?\"이라는 질문이 주어졌을 때, memory.get_current_entities()는 이 질문에서 중요한 정보, 즉 **\"Shelly Kim\"**이라는 사람 이름을 개체로 인식\n",
        "memory.get_current_entities({\"input\": \"Who is Shelly Kim?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fe430b",
      "metadata": {},
      "source": [
        "### get_knowledge_triplets(input_string: str) → List[KnowledgeTriple]\n",
        "\n",
        "The `get_knowledge_triplets` method operates as follows:\n",
        "\n",
        "**1. Knowledge Triple Extraction Chain**\n",
        "- Creates an `LLMChain` using the `knowledge_triplet_extraction_prompt` template.\n",
        "- Designed to extract triples in (**subject-relation-object**) format from given text.\n",
        "\n",
        "**2. Memory Search**\n",
        "- Searches for information related to \"Shelly\" from previously stored conversations.\n",
        "- Stored context:\n",
        "  - \"This is Shelly Kim who lives in Pangyo.\"\n",
        "  - \"Shelly Kim is our company's new designer.\"\n",
        "\n",
        "**3. Triple Extraction**\n",
        "- Generates the following triples from the retrieved information:\n",
        "  - (Shelly Kim, lives in, Pangyo)\n",
        "  - (Shelly Kim, is, designer)\n",
        "  - (Shelly Kim, works at, our company)\n",
        "\n",
        "This method extracts relationship information in **triple format** from all stored conversation content **related to a specific entity**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cb102317",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([KnowledgeTriple(subject='Shelly Kim', predicate='lives in', object_='Pangyo'),\n",
              "  KnowledgeTriple(subject='Shelly Kim', predicate='is', object_=\"company's new designer\")],\n",
              " '\\n',\n",
              " [KnowledgeTriple(subject='Shelly Kim', predicate='lives in', object_='Pangyo')],\n",
              " '\\n',\n",
              " [KnowledgeTriple(subject='Shelly Kim', predicate='is a', object_='designer')],\n",
              " '\\n',\n",
              " [])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# KG 그래프에서 입력된 정보를 기반으로 관련된 Triplets를 반환\n",
        "# Triplets 주어(subject) - 관계(predicate) - 목적어(object) 형식\n",
        "\n",
        "\n",
        "memory.get_knowledge_triplets({\"input\": \"Shelly\"}), \"\\n\", memory.get_knowledge_triplets(\n",
        "    {\"input\": \"Pangyo\"}\n",
        "), \"\\n\", memory.get_knowledge_triplets(\n",
        "    {\"input\": \"designer\"}\n",
        "), \"\\n\", memory.get_knowledge_triplets(\n",
        "    {\"input\": \"Langchain\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "662b3831",
      "metadata": {},
      "source": [
        "### load_memory_variables(inputs: Dict[str, Any]) → Dict[str, Any]\n",
        "\n",
        "The `load_memory_variables` method operates through the following steps:\n",
        "\n",
        "**1. Entity Extraction**\n",
        "- Extracts entities (e.g., \"Shelly Kim\") from the input \"Who is Shelly Kim?\"\n",
        "- Internally uses the `get_current_entities` method.\n",
        "\n",
        "**2. Knowledge Retrieval**\n",
        "- Searches for all knowledge triplets related to the extracted entities.\n",
        "- Queries the graph for information previously stored via `save_context`\n",
        "\n",
        "**3. Information Formatting**\n",
        "- Converts found triplets into system messages.\n",
        "- Returns a list of message objects due to the `return_messages=True` setting.\n",
        "\n",
        "This method retrieves relevant information from the stored knowledge graph and returns it in a structured format, which can then be used as context for subsequent conversations with the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "92d6929d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [SystemMessage(content=\"On Shelly Kim: Shelly Kim lives in Pangyo. Shelly Kim is our company's new designer.\", additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": \"Who is Shelly Kim?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa00c3f4",
      "metadata": {},
      "source": [
        "## Applying KG Memory to Chain\n",
        "\n",
        "This section demonstrates how to use `ConversationKGMemory` with `ConversationChain`\n",
        "\n",
        "(The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. If you want, you can skip to [Applying KG Memory with LCEL](#applying-kg-memory-with-lcel))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b020b140",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.memory.kg import ConversationKGMemory\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
        "The AI is talkative and provides lots of specific details from its context. \n",
        "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
        "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
        "\n",
        "Relevant Information:\n",
        "\n",
        "{history}\n",
        "\n",
        "Conversation:\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "\n",
        "\n",
        "#ConversationChain\n",
        "# 대화형 AI 시스템을 구축하는 클래스입니다. 이 클래스는 언어 모델(LLM), 프롬프트(Prompt), 그리고 **메모리(Memory)**를 사용하여 대화의 흐름을 관리\n",
        "\n",
        "#ConversationKGMemory\n",
        "# 대화의 기억을 관리하는 메모리 시스템\n",
        "\n",
        "#ConversationChain과 ConversationKGMemory는 대화형 AI 시스템을 만들 때 대화 흐름을 잘 관리하고, 대화 중에 얻은 정보를 기억하고 연결된 지식을 활용\n",
        "\n",
        "conversation_with_kg = ConversationChain(\n",
        "    llm=llm, prompt=prompt, memory=ConversationKGMemory(llm=llm)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf33db4",
      "metadata": {},
      "source": [
        "Let's initialize the conversation with some basic information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e25d23b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hi Teddy! It's nice to meet you. It sounds like you and Shelly are working together in a creative environment. Being a new designer, Shelly might be bringing fresh ideas and perspectives to your projects. How has it been working with her so far?\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#주어진 입력에 대해 AI 모델이 예측된 응답을 생성하는 함수\n",
        "\n",
        "conversation_with_kg.predict(\n",
        "    input=\"My name is Teddy. Shelly is a coworker of mine, and she's a new designer at our company.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de4d10e7",
      "metadata": {},
      "source": [
        "Let's query the memory for information about Shelly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c0e71b6e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': 'On Shelly: Shelly is a coworker of Teddy. Shelly is a new designer. Shelly works at our company.'}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Shelly에 대한 정보를 대화형 메모리 시스템에서 찾아서 반환하는 메서드\n",
        "\n",
        "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shelly?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc034d9b",
      "metadata": {},
      "source": [
        "You can also reset the memory by `memory.clear()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "208b5e4b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': ''}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_kg.memory.clear()\n",
        "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shelly?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8d42f5",
      "metadata": {},
      "source": [
        "## Applying KG Memory with LCEL\n",
        "\n",
        "Let's examine the memory after having a conversation using a custom `ConversationChain` with `ConversationKGMemory` by LCEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1905d380",
      "metadata": {},
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_community.memory.kg import ConversationKGMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"The following is a friendly conversation between a human and an AI. \n",
        "The AI is talkative and provides lots of specific details from its context. \n",
        "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
        "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
        "\n",
        "Relevant Information:\n",
        "{history}\"\"\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory = ConversationKGMemory(llm=llm, return_messages=True, memory_key=\"history\")\n",
        "\n",
        "\n",
        "class ConversationChain:\n",
        "    def __init__(self, prompt, llm, memory):\n",
        "        self.memory = memory\n",
        "        self.chain = (\n",
        "            RunnablePassthrough() #입력을 전달하는 역할\n",
        "            | RunnablePassthrough.assign( #메모리에서 대화 기록(history)을 로드하여 할당하는\n",
        "                history=RunnableLambda(memory.load_memory_variables)\n",
        "                | itemgetter(\"history\")\n",
        "            )\n",
        "            | prompt\n",
        "            | llm\n",
        "        )\n",
        "\n",
        "    def invoke(self, input_dict): \n",
        "        response = self.chain.invoke(input_dict) #주어진 입력(input_dict)을 self.chain을 통해 처리하고, 응답을 생성\n",
        "        self.memory.save_context(input_dict, {\"output\": response.content})\n",
        "        return response\n",
        "\n",
        "\n",
        "conversation_with_kg = ConversationChain(prompt, llm, memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07ca6c16",
      "metadata": {},
      "source": [
        "Let's initialize the conversation with some basic information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "99ac927b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hi Teddy! It's nice to meet you. It sounds like you and Shelly are working together at your company. How's everything going with the new designer on board?\""
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = conversation_with_kg.invoke( #사용자의 입력을 처리\n",
        "    {\n",
        "        \"input\": \"My name is Teddy. Shelly is a coworker of mine, and she's a new designer at our company.\"\n",
        "    }\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514ea4d8",
      "metadata": {},
      "source": [
        "Let's query the memory for information about Shelly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c18820be",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [SystemMessage(content='On Shelly: Shelly is a coworker of Teddy. Shelly is a new designer. Shelly works at our company.', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  메모리 시스템에서 특정 기억 변수를 로드하는 메서드\n",
        "# \"who is Shelly?\"라는 질문을 입력으로 주고, 이에 대한 과거의 대화 기록을 메모리에서 가져오는 작업을 수행\n",
        "\n",
        "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shelly?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a14d527d",
      "metadata": {},
      "source": [
        "You can also reset the memory by `memory.clear()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3dfac660",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': []}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_with_kg.memory.clear()\n",
        "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shelly?\"})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial-A2cWC-y3-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
